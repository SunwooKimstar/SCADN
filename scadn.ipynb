{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image\n",
    "import argparse\n",
    "from mmcv import Config\n",
    "from src.experiments import ExpMvtec\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--config_file', default ='./configs/config_mvtec.py', help='the path of config file')\n",
    "parser.add_argument('--path', '--checkpoints', type=str, default='./checkpoints', help='model checkpoints path (default: ./checkpoints)')\n",
    "parser.add_argument('--dataset', type=str, default = 'MVTecAD', help='Dataset name:CIFAR|MvtecAD')\n",
    "parser.add_argument('--subset', type=str, help='subset name (default: None)')\n",
    "parser.add_argument('--gpu', type=str, help='gpu list')\n",
    "parser.add_argument('--input', type=str, help='path to the input images directory or an input image')\n",
    "parser.add_argument('--val', type=str, help='path to the val images directory')\n",
    "parser.add_argument('--mask', type=str, help='path to the masks directory or a mask file')\n",
    "parser.add_argument('--output', type=str, help='path to the output directory')\n",
    "parser.add_argument('--debug', type=int, help='if not 0 will save debug image')\n",
    "parser.add_argument('--stage', type=int, help='if not 0 will save debug image')\n",
    "\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(config_file='./configs/config_mvtec.py', dataset='MVTecAD', debug=None, gpu=None, input=None, mask=None, output=None, path='./checkpoints', stage=None, subset='bottle', val=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.subset = 'bottle'\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config (path: ./configs/config_mvtec.py): {'MODE': 1, 'MASK_TYPE': 3, 'SEED': 10, 'GPU': [0], 'DEBUG': 0, 'VERBOSE': 0, 'dataroot': './dataset/mvtec', 'workers': 4, 'normal_class': 'good', 'TRAIN_MASK_FLIST': './mask', 'TEST_MASK_FLIST': './mask', 'LR': 0.0001, 'D2G_LR': 0.1, 'BETA1': 0.0, 'BETA2': 0.9, 'BATCH_SIZE': 4, 'INPUT_SIZE': 512, 'INPUT_CHANNELS': 3, 'SCALES': [1, 2, 3], 'MAX_EPOCHS': 200, 'REC_LOSS_WEIGHT': 1, 'FM_LOSS_WEIGHT': 0, 'INPAINT_ADV_LOSS_WEIGHT': 0.001, 'GAN_LOSS': 'nsgan', 'LOG_INTERVAL': 10, 'STAGE': [1], 'DATASET': 'MvTecAD', 'SUB_SET': '', 'PATH': './ckpt/mvtec'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mmcv import Config\n",
    "\n",
    "config = Config.fromfile('./configs/config_mvtec.py')\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config (path: ./configs/config_mvtec.py): {'MODE': 1, 'MASK_TYPE': 3, 'SEED': 10, 'GPU': [0], 'DEBUG': 0, 'VERBOSE': 0, 'dataroot': './dataset/mvtec', 'workers': 4, 'normal_class': 'good', 'TRAIN_MASK_FLIST': './mask', 'TEST_MASK_FLIST': './mask', 'LR': 0.0001, 'D2G_LR': 0.1, 'BETA1': 0.0, 'BETA2': 0.9, 'BATCH_SIZE': 4, 'INPUT_SIZE': 512, 'INPUT_CHANNELS': 3, 'SCALES': [1, 2, 3], 'MAX_EPOCHS': 200, 'REC_LOSS_WEIGHT': 1, 'FM_LOSS_WEIGHT': 0, 'INPAINT_ADV_LOSS_WEIGHT': 0.001, 'GAN_LOSS': 'nsgan', 'LOG_INTERVAL': 10, 'STAGE': [1], 'DATASET': 'MVTecAD', 'SUB_SET': '', 'PATH': './ckpt/mvtec'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if args.dataset is not None :\n",
    "    config.DATASET = 'MVTecAD'\n",
    "config"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé≠ **Multi-scale striped masks**\n",
    "- directions : horizontal, vertical (2Í∞ÄÏßÄ)\n",
    "- width : scale (4Í∞ÄÏßÄ)\n",
    "\n",
    "Ï¥ù 8Í∞ÄÏßÄÏùò Ï°∞Ìï©*2(Î∞òÏ†Ñ)ÏúºÎ°ú Íµ¨ÏÑ±ÎêòÎ©∞ **multi-scale mask** ÏÉùÏÑ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./mask/512_4_2.png',\n",
       " './mask/512_4_1.png',\n",
       " './mask/512_4_3.png',\n",
       " './mask/512_8_2.png',\n",
       " './mask/512_2_1.png',\n",
       " './mask/512_1_2.png',\n",
       " './mask/512_2_0.png',\n",
       " './mask/512_2_3.png',\n",
       " './mask/512_2_2.png',\n",
       " './mask/512_4_0.png',\n",
       " './mask/512_8_1.png',\n",
       " './mask/512_1_3.png',\n",
       " './mask/512_1_0.png',\n",
       " './mask/512_8_0.png',\n",
       " './mask/512_1_1.png',\n",
       " './mask/512_8_3.png']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flist = glob.glob(config.TRAIN_MASK_FLIST + '/*.png')\n",
    "flist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x720 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize = (20,10))\n",
    "plt.tight_layout()\n",
    "cols = 8\n",
    "rows = 2\n",
    "i = 1\n",
    "\n",
    "for filename in flist:\n",
    "    img = cv2.imread(filename)\n",
    "    ax = fig.add_subplot(rows, cols, i)\n",
    "    ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    ax.set_xticks([]), ax.set_yticks([])\n",
    "    i += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# any mode\n",
    "# if args.dataset is not None:\n",
    "#     config.append('DATASET', args.dataset)\n",
    "\n",
    "if args.subset is not None:\n",
    "    config.SUB_SET = args.subset\n",
    "if args.gpu is not None:\n",
    "    config.GPU = list(args.gpu)\n",
    "if args.stage is not None:\n",
    "    config.STAGE = [args.stage]\n",
    "\n",
    "if config.SUB_SET is not None:\n",
    "    config.SUB_SET = str(config.SUB_SET)\n",
    "    config.PATH = os.path.join(config.PATH, config.SUB_SET)\n",
    "\n",
    "# create checkpoints path if does't exist\n",
    "if not os.path.exists(config.PATH):\n",
    "    os.makedirs(config.PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config (path: ./configs/config_mvtec.py): {'MODE': 1, 'MASK_TYPE': 3, 'SEED': 10, 'GPU': [0], 'DEBUG': 0, 'VERBOSE': 0, 'dataroot': './dataset/mvtec', 'workers': 4, 'normal_class': 'good', 'TRAIN_MASK_FLIST': './mask', 'TEST_MASK_FLIST': './mask', 'LR': 0.0001, 'D2G_LR': 0.1, 'BETA1': 0.0, 'BETA2': 0.9, 'BATCH_SIZE': 4, 'INPUT_SIZE': 512, 'INPUT_CHANNELS': 3, 'SCALES': [1, 2, 3], 'MAX_EPOCHS': 200, 'REC_LOSS_WEIGHT': 1, 'FM_LOSS_WEIGHT': 0, 'INPAINT_ADV_LOSS_WEIGHT': 0.001, 'GAN_LOSS': 'nsgan', 'LOG_INTERVAL': 10, 'STAGE': [1], 'DATASET': 'MVTecAD', 'SUB_SET': 'bottle', 'PATH': './ckpt/mvtec/bottle'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sunwookim/.local/lib/python3.6/site-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"
     ]
    }
   ],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = ','.join(str(e) for e in config.GPU)\n",
    "\n",
    "# init device\n",
    "if torch.cuda.is_available():\n",
    "    config.DEVICE = torch.device(\"cuda\")\n",
    "    torch.backends.cudnn.benchmark = True   # cudnn auto-tuner\n",
    "else:\n",
    "    config.DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "# set cv2 running threads to 1 (prevents deadlocks with pytorch dataloader)\n",
    "cv2.setNumThreads(0)\n",
    "\n",
    "# initialize random seed\n",
    "torch.manual_seed(config.SEED)\n",
    "torch.cuda.manual_seed_all(config.SEED)\n",
    "np.random.seed(config.SEED)\n",
    "random.seed(config.SEED)\n",
    "\n",
    "model = ExpMvtec(config)\n",
    "model.load()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExpMvtec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from src.models import InpaintingModel\n",
    "from src.utils import Progbar\n",
    "from src.metrics import PSNR\n",
    "from src.evaluate import evaluate\n",
    "from src.dataset import load_data, BlockMask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpMvtec():\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "\n",
    "        model_name = 'coarse'\n",
    "        if 2 in config.STAGE:\n",
    "            model_name = 'fine'\n",
    "\n",
    "        self.debug = False\n",
    "        self.model_name = model_name\n",
    "        self.epoch = 0\n",
    "        self.inpaint_model = InpaintingModel(config).to(config.DEVICE)\n",
    "        self.scale_norm = [1 for _ in range(len(config.SCALES))]\n",
    "\n",
    "        self.psnr = PSNR(255.0).to(config.DEVICE)\n",
    "        self.mask_set = BlockMask(config)\n",
    "        self.dataset = load_data(config)\n",
    "        mask_loader = DataLoader(dataset=self.mask_set, batch_size=1)\n",
    "        self.masks = [x.to(self.config.DEVICE) for x in mask_loader]\n",
    "\n",
    "        self.results_path = os.path.join(config.PATH, 'results')\n",
    "\n",
    "        if hasattr(config, 'RESULTS'):\n",
    "            self.results_path = os.path.join(config.RESULTS)\n",
    "\n",
    "        if hasattr(config, 'DEBUG') and config.DEBUG != 0:\n",
    "            self.debug = True\n",
    "\n",
    "        self.log_file = os.path.join(config.PATH, 'log_' + model_name + '.dat')\n",
    "\n",
    "    def load(self):\n",
    "        self.inpaint_model.load()\n",
    "\n",
    "    def save(self):\n",
    "        self.inpaint_model.save()\n",
    "\n",
    "    def train(self):\n",
    "        train_loader = self.dataset['train']\n",
    "\n",
    "        keep_training = True\n",
    "        min_error = 1\n",
    "        max_epoch = int(float(self.config.MAX_EPOCHS))\n",
    "        total = len(train_loader.dataset)\n",
    "\n",
    "        if total == 0:\n",
    "            print('No training data was provided! Check \\'TRAIN_FLIST\\' value in the configuration file.')\n",
    "            return\n",
    "\n",
    "        while keep_training:\n",
    "            if 1 in self.config.STAGE:\n",
    "                self.inpaint_model.epoch += 1\n",
    "                self.epoch = self.inpaint_model.epoch\n",
    "                print('\\n\\nTraining proposal epoch: %d' % self.epoch)\n",
    "                progbar = Progbar(total, width=20, stateful_metrics=['epoch', 'iter'])\n",
    "                for items in train_loader:\n",
    "                    self.inpaint_model.train()\n",
    "                    images, masks, label = items\n",
    "                    images, masks = self.cuda(images, masks)\n",
    "\n",
    "                    # inpaint model\n",
    "                    # train\n",
    "                    outputs, gen_loss, dis_loss, logs = self.inpaint_model.process(images, masks)\n",
    "\n",
    "                    # backward\n",
    "                    self.inpaint_model.backward(gen_loss, dis_loss)\n",
    "\n",
    "                    logs[\"epoch\"] = self.epoch\n",
    "                    logs[\"iter\"] = self.inpaint_model.iteration\n",
    "\n",
    "                    progbar.add(len(images), values=logs.items() if self.config.VERBOSE else [x for x in logs.items() if not x[0].startswith('l_')])\n",
    "\n",
    "            # log model at checkpoints\n",
    "            if self.config.LOG_INTERVAL and self.epoch % self.config.LOG_INTERVAL == 0:\n",
    "                error1 = self.eval()\n",
    "                auc1 = self.test()\n",
    "                self.log([auc1, error1])\n",
    "                if error1 <= min_error:\n",
    "                    min_error = error1\n",
    "                    self.save()\n",
    "\n",
    "            if self.epoch >= max_epoch:\n",
    "                break\n",
    "\n",
    "        print('\\nEnd training....')\n",
    "\n",
    "    def eval(self):\n",
    "        print('\\n\\nval:')\n",
    "        val_loader = self.dataset['train4val']\n",
    "\n",
    "        total = len(val_loader.dataset)\n",
    "        self.inpaint_model.eval()\n",
    "\n",
    "        mean_error = 0\n",
    "        progbar = Progbar(total, width=20, stateful_metrics=['it'])\n",
    "        for index, items in enumerate(val_loader):\n",
    "            images, masks = self.cuda(*items[0:2])\n",
    "\n",
    "            # inpaint model\n",
    "            error1_list, mix_out_list_x, mix_out_list_y = self.get_error_map_for_some_scales(images, self.masks, metric='L1',\n",
    "                                                                           scales=self.config.SCALES, output=True)\n",
    "            error1 = self.get_max_select_error(error1_list)\n",
    "            mean_error += torch.mean(error1) * len(items[0]) / total\n",
    "\n",
    "            progbar.add(len(images), values=[('index', index)])\n",
    "        return mean_error.item()\n",
    "\n",
    "    def test(self):\n",
    "        print('\\n\\ntest:')\n",
    "        self.inpaint_model.eval()\n",
    "\n",
    "        test_loader = self.dataset['test']\n",
    "\n",
    "        total = len(test_loader.dataset)\n",
    "\n",
    "        an_scores1 = torch.zeros(size=(total,), dtype=torch.float32, device=self.config.DEVICE)\n",
    "        gt_labels = torch.zeros(size=(total,), dtype=torch.long, device=self.config.DEVICE)\n",
    "        select_scale = torch.zeros(size=(total,), dtype=torch.long, device=self.config.DEVICE)\n",
    "        progbar = Progbar(total, width=20, stateful_metrics=['it'])\n",
    "        for index, items in enumerate(test_loader):\n",
    "            start_index = index * test_loader.batch_size\n",
    "            end_index = start_index + items[0].shape[0]\n",
    "            images, masks, label = items\n",
    "            images, masks = self.cuda(images, masks)\n",
    "\n",
    "            # inpaint model\n",
    "            error1_list, mix_out_list_x, mix_out_list_y = self.get_error_map_for_some_scales(images, self.masks, metric='MSE',\n",
    "                                                                           scales=self.config.SCALES, output=True)\n",
    "            error1, max_scale_ind = self.get_max_select_error(error1_list, need_arg=True)\n",
    "            select_scale[start_index: end_index] = max_scale_ind\n",
    "            an_scores1[start_index: end_index] = torch.mean(error1, [1, 2])\n",
    "            gt_labels[start_index: end_index] = label\n",
    "            progbar.add(len(images), values=[('index', index)])\n",
    "        an_scores1 = (an_scores1 - torch.min(an_scores1)) / (torch.max(an_scores1) - torch.min(an_scores1))\n",
    "        # metrics\n",
    "        auc1 = evaluate(gt_labels, an_scores1)\n",
    "        print(auc1)\n",
    "        return auc1\n",
    "\n",
    "    def get_error_map_coarse(self, images, mask_loader, metric='MSE'):\n",
    "        if metric == 'MSE':\n",
    "            error_metric = nn.MSELoss(reduction='none')\n",
    "        else:\n",
    "            error_metric = nn.L1Loss(reduction='none')\n",
    "        with torch.no_grad():\n",
    "            error = []\n",
    "            raw_output = []\n",
    "            sum_mask = []\n",
    "            error_map_list = []\n",
    "            for i, masks in enumerate(mask_loader):\n",
    "                masks = masks.to(self.config.DEVICE)\n",
    "                outputs = self.inpaint_model(images, masks)\n",
    "                error.append(torch.mean(error_metric(outputs, images) * masks, 1))  # mean RGB channel\n",
    "                raw_output.append(outputs * masks)\n",
    "                sum_mask.append(masks)\n",
    "            error = torch.stack(tuple(error))\n",
    "            raw_output = torch.stack(tuple(raw_output))\n",
    "            sum_mask = torch.stack(tuple(sum_mask))\n",
    "            for index in range(0, self.config.SCALES*4, 4):\n",
    "                sum_mask_t = sum_mask[index: index+4]\n",
    "                sum_mask_t = torch.sum(sum_mask_t, 0)\n",
    "                sum_mask_t = torch.reciprocal(sum_mask_t)\n",
    "                sum_mask_t[sum_mask_t == float('inf')] = 0\n",
    "                error_map_list.append(torch.sum(error[index: index+4] * sum_mask_t, 0))\n",
    "\n",
    "            for i, error_map in enumerate(error_map_list):\n",
    "                error_map_list[i] = error_map / self.scale_norm[i]\n",
    "            error_map_merge = torch.stack(error_map_list)\n",
    "            error_map_merge = torch.mean(error_map_merge, 0)\n",
    "            # error_map_merge, _ = torch.max(error_map_merge, 0)\n",
    "            mix_output = torch.sum(raw_output[0:4], 0)\n",
    "        return error_map_merge, mix_output\n",
    "\n",
    "    def get_error_map_for_some_scales(self, images, mask_loader, metric='MSE', scales=None, output=False):\n",
    "        if metric == 'MSE':\n",
    "            error_metric = nn.MSELoss(reduction='none')\n",
    "        else:\n",
    "            error_metric = nn.L1Loss(reduction='none')\n",
    "        with torch.no_grad():\n",
    "            error_map_list = []\n",
    "            mix_output_x = []\n",
    "            mix_output_y = []\n",
    "            for scale in scales:\n",
    "                error = []\n",
    "                raw_output = []\n",
    "                for masks in mask_loader[scale*4:(scale+1)*4]:\n",
    "                    outputs = self.inpaint_model(images, masks)\n",
    "                    if output:\n",
    "                        raw_output.append(outputs*masks)\n",
    "                    error.append(torch.mean(error_metric(outputs, images) * masks, 1))  # mean RGB channel\n",
    "                if output:\n",
    "                    raw_output = torch.stack(raw_output)\n",
    "                    mix_output_x.append(torch.sum(raw_output[0:2], 0))\n",
    "                    mix_output_y.append(torch.sum(raw_output[2:4], 0))\n",
    "                error = torch.stack(tuple(error))\n",
    "                # error_map_list.append(torch.sum(error * 0.5, 0))\n",
    "                error_map_list.append(torch.max(error, 0)[0])\n",
    "\n",
    "        return error_map_list, mix_output_x, mix_output_y\n",
    "\n",
    "\n",
    "    def get_mean_merged_error(self, error_map_list):\n",
    "        error_map_merge = torch.stack(error_map_list)\n",
    "        error_map_merge = torch.mean(error_map_merge, 0)\n",
    "        return error_map_merge\n",
    "\n",
    "    def get_max_select_error(self, error_map_list, need_arg=False):\n",
    "        error_map_list = torch.stack(error_map_list)\n",
    "        mean_errors = torch.mean(error_map_list, (2, 3))\n",
    "        for i, scale in enumerate(self.config.SCALES):\n",
    "            # mean_errors[i] = mean_errors[i] / self.scale_norm[i]\n",
    "            mean_errors[i] = mean_errors[i] - self.scale_norm[i]\n",
    "        mean_errors, max_scale_ind = torch.max(mean_errors, dim=0)  # [batch]\n",
    "        error_map_merge = torch.stack([error_map_list[j, i] for i, j in enumerate(max_scale_ind)])\n",
    "        # error_map_merge = torch.mean(error_map_merge, 0)\n",
    "        if need_arg:\n",
    "            return error_map_merge, max_scale_ind\n",
    "        else:\n",
    "            return error_map_merge\n",
    "\n",
    "\n",
    "    def get_error_map_coarse_center(self, images, mask_loader, metric='MSE'):\n",
    "        if metric == 'MSE':\n",
    "            error_metric = nn.MSELoss(reduction='none')\n",
    "        else:\n",
    "            error_metric = nn.L1Loss(reduction='none')\n",
    "        error = 0\n",
    "        raw_output = 0\n",
    "        with torch.no_grad():\n",
    "            for i, masks in enumerate(mask_loader):\n",
    "                masks = masks.to(self.config.DEVICE)\n",
    "                outputs = self.inpaint_model(images, masks)\n",
    "                error = torch.mean(error_metric(outputs, images) * masks, 1)  # mean RGB channel\n",
    "                raw_output = outputs * masks + images * (1-masks)\n",
    "\n",
    "        return error, raw_output\n",
    "\n",
    "\n",
    "    def update_norm(self):\n",
    "        print('\\n\\nupdate normalization parameter:')\n",
    "        val_loader = self.dataset['train4val']\n",
    "\n",
    "        total = len(val_loader.dataset)\n",
    "        self.inpaint_model.eval()\n",
    "\n",
    "        mean_error_scales = {str(i): 0 for i in self.config.SCALES}\n",
    "        progbar = Progbar(total, width=20, stateful_metrics=['it'])\n",
    "        for index, items in enumerate(val_loader):\n",
    "            images, masks = self.cuda(*items[0:2])\n",
    "            # inpaint model\n",
    "            error1_list, mix_out_list_x, mix_out_list_y = self.get_error_map_for_some_scales(images, self.masks, metric='MSE',\n",
    "                                                                           scales=self.config.SCALES, output=True)\n",
    "            for i, scale in enumerate(self.config.SCALES):\n",
    "                mean_error_scales[str(scale)] += torch.mean(error1_list[i]) * len(items[0]) / total\n",
    "            progbar.add(len(images), values=[('index', index)])\n",
    "        # update\n",
    "        for i, scale in enumerate(self.config.SCALES):\n",
    "            self.scale_norm[i] = mean_error_scales[str(scale)].item()\n",
    "        print('updated norm:', self.scale_norm)\n",
    "\n",
    "    def log(self, logs):\n",
    "        with open(self.log_file, 'a') as f:\n",
    "            f.write('%s\\n' % ' '.join([str(item) for item in logs]))\n",
    "\n",
    "    def cuda(self, *args):\n",
    "        return (item.to(self.config.DEVICE) for item in args)\n",
    "\n",
    "    def postprocess(self, img):\n",
    "        # [0, 1] => [0, 255]\n",
    "        img = img * 255.0\n",
    "        img = img.permute(0, 2, 3, 1)\n",
    "        return img.int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InpaintingModel(\n",
       "  (generator): InpaintGenerator(\n",
       "    (encoder): Sequential(\n",
       "      (0): ReflectionPad2d((3, 3, 3, 3))\n",
       "      (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
       "      (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (9): ReLU(inplace=True)\n",
       "      (10): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (11): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (12): ReLU(inplace=True)\n",
       "    )\n",
       "    (middle): Sequential(\n",
       "      (0): ResnetBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): ReflectionPad2d((2, 2, 2, 2))\n",
       "          (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\n",
       "          (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (1): ResnetBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): ReflectionPad2d((2, 2, 2, 2))\n",
       "          (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\n",
       "          (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (2): ResnetBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): ReflectionPad2d((2, 2, 2, 2))\n",
       "          (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\n",
       "          (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (3): ResnetBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): ReflectionPad2d((2, 2, 2, 2))\n",
       "          (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\n",
       "          (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (4): ResnetBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): ReflectionPad2d((2, 2, 2, 2))\n",
       "          (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\n",
       "          (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (5): ResnetBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): ReflectionPad2d((2, 2, 2, 2))\n",
       "          (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\n",
       "          (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (6): ResnetBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): ReflectionPad2d((2, 2, 2, 2))\n",
       "          (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\n",
       "          (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (7): ResnetBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): ReflectionPad2d((2, 2, 2, 2))\n",
       "          (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\n",
       "          (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (5): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (7): ReLU(inplace=True)\n",
       "      (8): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (9): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (10): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): ReflectionPad2d((3, 3, 3, 3))\n",
       "      (13): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (discriminator): Discriminator(\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (conv3): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (conv4): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (conv5): Sequential(\n",
       "      (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (l1_loss): MSELoss()\n",
       "  (adversarial_loss): AdversarialLoss(\n",
       "    (criterion): BCELoss()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.inpaint_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.dataset.BlockMask at 0x7fc601b515c0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.mask_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[1., 1., 1.,  ..., 0., 0., 0.],\n",
       "           [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "           [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "           [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "           [1., 1., 1.,  ..., 0., 0., 0.]]]], device='cuda:0'),\n",
       " tensor([[[[0., 0., 0.,  ..., 1., 1., 1.],\n",
       "           [0., 0., 0.,  ..., 1., 1., 1.],\n",
       "           [0., 0., 0.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 1., 1., 1.],\n",
       "           [0., 0., 0.,  ..., 1., 1., 1.],\n",
       "           [0., 0., 0.,  ..., 1., 1., 1.]]]], device='cuda:0'),\n",
       " tensor([[[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]]], device='cuda:0')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.masks[:3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from src.models import InpaintingModel\n",
    "from src.utils import Progbar\n",
    "from src.metrics import PSNR\n",
    "from src.evaluate import evaluate\n",
    "from src.dataset import load_data, BlockMask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InpaintingModel(\n",
       "  (generator): InpaintGenerator(\n",
       "    (encoder): Sequential(\n",
       "      (0): ReflectionPad2d((3, 3, 3, 3))\n",
       "      (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
       "      (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (9): ReLU(inplace=True)\n",
       "      (10): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (11): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (12): ReLU(inplace=True)\n",
       "    )\n",
       "    (middle): Sequential(\n",
       "      (0): ResnetBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): ReflectionPad2d((2, 2, 2, 2))\n",
       "          (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\n",
       "          (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (1): ResnetBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): ReflectionPad2d((2, 2, 2, 2))\n",
       "          (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\n",
       "          (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (2): ResnetBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): ReflectionPad2d((2, 2, 2, 2))\n",
       "          (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\n",
       "          (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (3): ResnetBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): ReflectionPad2d((2, 2, 2, 2))\n",
       "          (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\n",
       "          (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (4): ResnetBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): ReflectionPad2d((2, 2, 2, 2))\n",
       "          (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\n",
       "          (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (5): ResnetBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): ReflectionPad2d((2, 2, 2, 2))\n",
       "          (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\n",
       "          (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (6): ResnetBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): ReflectionPad2d((2, 2, 2, 2))\n",
       "          (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\n",
       "          (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (7): ResnetBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): ReflectionPad2d((2, 2, 2, 2))\n",
       "          (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\n",
       "          (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (5): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (7): ReLU(inplace=True)\n",
       "      (8): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (9): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (10): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): ReflectionPad2d((3, 3, 3, 3))\n",
       "      (13): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (discriminator): Discriminator(\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (conv3): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (conv4): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (conv5): Sequential(\n",
       "      (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (l1_loss): MSELoss()\n",
       "  (adversarial_loss): AdversarialLoss(\n",
       "    (criterion): BCELoss()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inpaint_model = InpaintingModel(config).to(config.DEVICE)\n",
    "inpaint_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_norm = [1 for _ in range(len(config.SCALES))]\n",
    "scale_norm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PSNR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSNR(nn.Module):\n",
    "    def __init__(self, max_val):\n",
    "        super(PSNR, self).__init__()\n",
    "\n",
    "        base10 = torch.log(torch.tensor(10.0))\n",
    "        max_val = torch.tensor(max_val).float()\n",
    "\n",
    "        self.register_buffer('base10', base10)\n",
    "        self.register_buffer('max_val', 20 * torch.log(max_val) / base10)\n",
    "\n",
    "    def __call__(self, a, b):\n",
    "        mse = torch.mean((a.float() - b.float()) ** 2)\n",
    "\n",
    "        if mse == 0:\n",
    "            return torch.tensor(0)\n",
    "\n",
    "        return self.max_val - 10 * torch.log(mse) / self.base10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "psnr = PSNR(255.0).to(config.DEVICE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- mask_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class BlockMask(torch.utils.data.Dataset):\n",
    "    def __init__(self, config):\n",
    "        self.flist = list(glob.glob(config.TRAIN_MASK_FLIST + '/*.jpg')) + list(glob.glob(config.TRAIN_MASK_FLIST + '/*.png'))\n",
    "        self.flist.sort()\n",
    "        self.mask_set = []\n",
    "        for mask_index in range(len(self.flist)):\n",
    "            mask = Image.open(self.flist[mask_index])\n",
    "            mask = transforms.Resize(config.INPUT_SIZE, Image.NEAREST)(mask)\n",
    "            self.mask_set.append(transforms.ToTensor()(mask))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.flist)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.mask_set[index]\n",
    "\n",
    "def load_data(opt):\n",
    "    \"\"\" Load Data\n",
    "\n",
    "    Args:\n",
    "        opt ([type]): Argument Parser\n",
    "\n",
    "    Raises:\n",
    "        IOError: Cannot Load Dataset\n",
    "\n",
    "    Returns:\n",
    "        [type]: dataloader\n",
    "    \"\"\"\n",
    "\n",
    "    ##\n",
    "    masks = AddMask(opt)\n",
    "    if opt.normal_class == '':\n",
    "        opt.normal_class = opt.SUB_SET\n",
    "    # LOAD DATA SET\n",
    "    if opt.dataroot == '':\n",
    "        opt.dataroot = './dataset/{}'.format(opt.DATASET)\n",
    "\n",
    "    if opt.DATASET in ['MVTecAD']:\n",
    "        if opt.SUB_SET is not None:\n",
    "            opt.dataroot = os.path.join(opt.dataroot, opt.SUB_SET)\n",
    "        splits = ['train', 'test', 'train4val']\n",
    "        splits2folder = {'train': 'train', 'test': 'test', 'train4val': 'train'}\n",
    "        drop_last_batch = {'train': True, 'test': False, 'train4val': False}\n",
    "        shuffle = {'train': True, 'test': False, 'train4val': False}\n",
    "        transform = transforms.Compose([transforms.Resize(opt.INPUT_SIZE),\n",
    "                                        transforms.CenterCrop(opt.INPUT_SIZE),\n",
    "                                        transforms.ToTensor(), ])\n",
    "                                        # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), ])\n",
    "\n",
    "        collate = {'train': masks.append_mask, 'test': masks.append_mask, 'train4val': masks.append_mask}\n",
    "        dataset = {x: ImageFolder(os.path.join(opt.dataroot, splits2folder[x]), transform) for x in splits}\n",
    "\n",
    "\n",
    "        dataset = {x: get_custom_anomaly_dataset(dataset[x], opt.normal_class) for x in dataset.keys()}\n",
    "        # dataset['train4val'] = dataset['train']\n",
    "        dataloader = {}\n",
    "        for x in splits:\n",
    "            if collate[x] is not None:\n",
    "                dataloader[x] = torch.utils.data.DataLoader(dataset=dataset[x],\n",
    "                                                            batch_size=opt.BATCH_SIZE,\n",
    "                                                            shuffle=shuffle[x],\n",
    "                                                            num_workers=int(opt.workers),\n",
    "                                                            drop_last=drop_last_batch[x],\n",
    "                                                            collate_fn=collate[x],\n",
    "                                                            worker_init_fn=(None if opt.SEED == -1\n",
    "                                                            else lambda x: np.random.seed(opt.SEED)))\n",
    "            else:\n",
    "                dataloader[x] = torch.utils.data.DataLoader(dataset=dataset[x],\n",
    "                                                            batch_size=opt.BATCH_SIZE,\n",
    "                                                            shuffle=shuffle[x],\n",
    "                                                            num_workers=int(opt.workers),\n",
    "                                                            drop_last=drop_last_batch[x],\n",
    "                                                            worker_init_fn=(None if opt.SEED == -1\n",
    "                                                                            else lambda x: np.random.seed(opt.SEED)))\n",
    "        return dataloader\n",
    "\n",
    "def get_custom_anomaly_dataset(subset, nrm_cls):\n",
    "    nrm_cls_idx = subset.class_to_idx[nrm_cls]\n",
    "    idx_to_class = {v: k for k, v in subset.class_to_idx.items()}\n",
    "    new_targets = [0 if x == nrm_cls_idx else 1 for x in subset.targets]\n",
    "    new_samples = [(x[0], 0 if x[1] == nrm_cls_idx else 1) for x in subset.samples]\n",
    "    subset.class_name = [idx_to_class[x] for x in subset.targets]\n",
    "    subset.targets = new_targets\n",
    "    subset.samples = new_samples\n",
    "    subset.imgs = new_samples\n",
    "    return subset\n",
    "\n",
    "class AddMask():\n",
    "    def __init__(self, config):\n",
    "        # self.flist = list(glob.glob(config.TRAIN_MASK_FLIST + '/*.jpg')) + list(glob.glob(config.TRAIN_MASK_FLIST + '/*.png'))\n",
    "        self.flist = glob.glob(config.TRAIN_MASK_FLIST + '/*.png')\n",
    "        self.flist.sort()\n",
    "        self.mask_set = []\n",
    "        self.mask_type = config.MASK_TYPE\n",
    "        for scale in config.SCALES:\n",
    "            for mask_index in range(scale*4, (scale+1)*4):\n",
    "                mask = Image.open(self.flist[mask_index])\n",
    "                mask = transforms.Resize(config.INPUT_SIZE, interpolation=Image.NEAREST)(mask)\n",
    "                # mask = (mask > 0).astype(np.uint8) * 255\n",
    "                self.mask_set.append(transforms.ToTensor()(mask))\n",
    "\n",
    "    def append_mask(self, batch):\n",
    "        masks = []\n",
    "        imgs = []\n",
    "        label = []\n",
    "        for i in range(len(batch)):\n",
    "            img, target = batch[i]\n",
    "            imgs.append(img)\n",
    "            masks.append(random.choice(self.mask_set))\n",
    "            label.append(target)\n",
    "        imgs = torch.stack(imgs, dim=0)\n",
    "        mask_batch = torch.stack(masks, dim=0)\n",
    "        label = torch.FloatTensor(label)\n",
    "        if self.mask_type == 0:\n",
    "            mask_batch = None\n",
    "        return imgs, mask_batch, label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- AddMask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./mask/512_4_2.png',\n",
       " './mask/512_4_1.png',\n",
       " './mask/512_4_3.png',\n",
       " './mask/512_8_2.png',\n",
       " './mask/512_2_1.png',\n",
       " './mask/512_1_2.png',\n",
       " './mask/512_2_0.png',\n",
       " './mask/512_2_3.png',\n",
       " './mask/512_2_2.png',\n",
       " './mask/512_4_0.png',\n",
       " './mask/512_8_1.png',\n",
       " './mask/512_1_3.png',\n",
       " './mask/512_1_0.png',\n",
       " './mask/512_8_0.png',\n",
       " './mask/512_1_1.png',\n",
       " './mask/512_8_3.png']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flist = glob.glob(config.TRAIN_MASK_FLIST + '/*.png')\n",
    "flist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale = config.SCALES\n",
    "scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "flist = glob.glob(config.TRAIN_MASK_FLIST + '/*.png')\n",
    "flist.sort()\n",
    "mask_set = []\n",
    "mask_type = config.MASK_TYPE\n",
    "for scale in config.SCALES:\n",
    "    for mask_index in range(scale*4, (scale+1)*4):\n",
    "        mask = Image.open(flist[mask_index])\n",
    "        mask = transforms.Resize(config.INPUT_SIZE, interpolation=Image.NEAREST)(mask)\n",
    "        # mask = (mask > 0).astype(np.uint8) * 255\n",
    "        mask_set.append(transforms.ToTensor()(mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgAAAAIAAQAAAADcA+lXAAAAl0lEQVR4nO3MIQ4AMAgEQeD/f251MQhEzay7XDJ54i3bnv6KZQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAB/gQt+WAYAPpZitgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=1 size=512x512 at 0x7FC6063A4EF0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_index = 4\n",
    "mask = Image.open(flist[mask_index])\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgAAAAIAAQAAAADcA+lXAAAAl0lEQVR4nO3MIQ4AMAgEQeD/f251MQhEzay7XDJ54i3bnv6KZQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAB/gQt+WAYAPpZitgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=1 size=512x512 at 0x7FC6063A4EF0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = transforms.Resize(config.INPUT_SIZE, interpolation=Image.NEAREST)(mask)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1.,  ..., 0., 0., 0.],\n",
       "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "         [1., 1., 1.,  ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_tens = transforms.ToTensor()(mask)\n",
    "mask_tens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[1., 1., 1.,  ..., 0., 0., 0.],\n",
       "          [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "          [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "          [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "          [1., 1., 1.,  ..., 0., 0., 0.]]]),\n",
       " tensor([[[0., 0., 0.,  ..., 1., 1., 1.],\n",
       "          [0., 0., 0.,  ..., 1., 1., 1.],\n",
       "          [0., 0., 0.,  ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 1., 1., 1.],\n",
       "          [0., 0., 0.,  ..., 1., 1., 1.],\n",
       "          [0., 0., 0.,  ..., 1., 1., 1.]]]),\n",
       " tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]])]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config (path: ./configs/config_mvtec.py): {'MODE': 1, 'MASK_TYPE': 3, 'SEED': 10, 'GPU': [0], 'DEBUG': 0, 'VERBOSE': 0, 'dataroot': './dataset/mvtec/bottle', 'workers': 4, 'normal_class': 'good', 'TRAIN_MASK_FLIST': './mask', 'TEST_MASK_FLIST': './mask', 'LR': 0.0001, 'D2G_LR': 0.1, 'BETA1': 0.0, 'BETA2': 0.9, 'BATCH_SIZE': 4, 'INPUT_SIZE': 512, 'INPUT_CHANNELS': 3, 'SCALES': [1, 2, 3], 'MAX_EPOCHS': 200, 'REC_LOSS_WEIGHT': 1, 'FM_LOSS_WEIGHT': 0, 'INPAINT_ADV_LOSS_WEIGHT': 0.001, 'GAN_LOSS': 'nsgan', 'LOG_INTERVAL': 10, 'STAGE': [1], 'DATASET': 'MVTecAD', 'SUB_SET': 'bottle', 'PATH': './ckpt/mvtec/bottle', 'DEVICE': device(type='cuda')}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sunwookim/.local/lib/python3.6/site-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"
     ]
    }
   ],
   "source": [
    "opt = config\n",
    "masks = AddMask(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'good'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.normal_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "if opt.normal_class == '':\n",
    "    opt.normal_class = opt.SUB_SET\n",
    "# LOAD DATA SET\n",
    "if opt.dataroot == '':\n",
    "    opt.dataroot = './dataset/{}'.format(opt.DATASET)\n",
    "\n",
    "opt.dataroot = './dataset/mvtec/bottle'\n",
    "\n",
    "if opt.DATASET in ['MVTecAD']:\n",
    "    # if opt.SUB_SET is not None:\n",
    "    #     opt.dataroot = os.path.join(opt.dataroot, opt.SUB_SET)\n",
    "    opt.dataroot = './dataset/mvtec/bottle'\n",
    "    splits = ['train', 'test', 'train4val']\n",
    "    splits2folder = {'train': 'train', 'test': 'test', 'train4val': 'train'}\n",
    "    drop_last_batch = {'train': True, 'test': False, 'train4val': False}\n",
    "    shuffle = {'train': True, 'test': False, 'train4val': False}\n",
    "    transform = transforms.Compose([transforms.Resize(opt.INPUT_SIZE),\n",
    "                                    transforms.CenterCrop(opt.INPUT_SIZE),\n",
    "                                    transforms.ToTensor(), ])\n",
    "                                    # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), ])\n",
    "\n",
    "    collate = {'train': masks.append_mask, 'test': masks.append_mask, 'train4val': masks.append_mask}\n",
    "    dataset = {x: ImageFolder(os.path.join(opt.dataroot, splits2folder[x]), transform) for x in splits}\n",
    "\n",
    "\n",
    "    dataset = {x: get_custom_anomaly_dataset(dataset[x], opt.normal_class) for x in dataset.keys()}\n",
    "    # dataset['train4val'] = dataset['train']\n",
    "    dataloader = {}\n",
    "    for x in splits:\n",
    "        if collate[x] is not None:\n",
    "            dataloader[x] = torch.utils.data.DataLoader(dataset=dataset[x],\n",
    "                                                        batch_size=opt.BATCH_SIZE,\n",
    "                                                        shuffle=shuffle[x],\n",
    "                                                        num_workers=int(opt.workers),\n",
    "                                                        drop_last=drop_last_batch[x],\n",
    "                                                        collate_fn=collate[x],\n",
    "                                                        worker_init_fn=(None if opt.SEED == -1\n",
    "                                                        else lambda x: np.random.seed(opt.SEED)))\n",
    "        else:\n",
    "            dataloader[x] = torch.utils.data.DataLoader(dataset=dataset[x],\n",
    "                                                        batch_size=opt.BATCH_SIZE,\n",
    "                                                        shuffle=shuffle[x],\n",
    "                                                        num_workers=int(opt.workers),\n",
    "                                                        drop_last=drop_last_batch[x],\n",
    "                                                        worker_init_fn=(None if opt.SEED == -1\n",
    "                                                                        else lambda x: np.random.seed(opt.SEED)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <bound method AddMask.append_mask of <__main__.AddMask object at 0x7fc601db5710>>,\n",
       " 'test': <bound method AddMask.append_mask of <__main__.AddMask object at 0x7fc601db5710>>,\n",
       " 'train4val': <bound method AddMask.append_mask of <__main__.AddMask object at 0x7fc601db5710>>}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'test', 'train4val'])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x7fc6010bfeb8>,\n",
       " 'test': <torch.utils.data.dataloader.DataLoader at 0x7fc6010bff98>,\n",
       " 'train4val': <torch.utils.data.dataloader.DataLoader at 0x7fc6010bf9b0>}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ExpMvtec : Mask_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sunwookim/.local/lib/python3.6/site-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"
     ]
    }
   ],
   "source": [
    "mask_set = BlockMask(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7fc60111c940>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_loader = DataLoader(dataset=mask_set, batch_size=1)\n",
    "mask_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mask_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 1., 1.,  ..., 0., 0., 0.],\n",
       "          [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "          [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "          [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "          [1., 1., 1.,  ..., 0., 0., 0.]]]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(mask_loader)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[1., 1., 1.,  ..., 0., 0., 0.],\n",
       "           [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "           [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "           [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "           [1., 1., 1.,  ..., 0., 0., 0.]]]], device='cuda:0'),\n",
       " tensor([[[[0., 0., 0.,  ..., 1., 1., 1.],\n",
       "           [0., 0., 0.,  ..., 1., 1., 1.],\n",
       "           [0., 0., 0.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 1., 1., 1.],\n",
       "           [0., 0., 0.,  ..., 1., 1., 1.],\n",
       "           [0., 0., 0.,  ..., 1., 1., 1.]]]], device='cuda:0'),\n",
       " tensor([[[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]]], device='cuda:0'),\n",
       " tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.]]]], device='cuda:0'),\n",
       " tensor([[[[1., 1., 1.,  ..., 0., 0., 0.],\n",
       "           [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "           [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "           [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "           [1., 1., 1.,  ..., 0., 0., 0.]]]], device='cuda:0'),\n",
       " tensor([[[[0., 0., 0.,  ..., 1., 1., 1.],\n",
       "           [0., 0., 0.,  ..., 1., 1., 1.],\n",
       "           [0., 0., 0.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 1., 1., 1.],\n",
       "           [0., 0., 0.,  ..., 1., 1., 1.],\n",
       "           [0., 0., 0.,  ..., 1., 1., 1.]]]], device='cuda:0'),\n",
       " tensor([[[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]]], device='cuda:0'),\n",
       " tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.]]]], device='cuda:0'),\n",
       " tensor([[[[1., 1., 1.,  ..., 0., 0., 0.],\n",
       "           [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "           [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "           [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "           [1., 1., 1.,  ..., 0., 0., 0.]]]], device='cuda:0'),\n",
       " tensor([[[[0., 0., 0.,  ..., 1., 1., 1.],\n",
       "           [0., 0., 0.,  ..., 1., 1., 1.],\n",
       "           [0., 0., 0.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 1., 1., 1.],\n",
       "           [0., 0., 0.,  ..., 1., 1., 1.],\n",
       "           [0., 0., 0.,  ..., 1., 1., 1.]]]], device='cuda:0'),\n",
       " tensor([[[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]]], device='cuda:0'),\n",
       " tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.]]]], device='cuda:0'),\n",
       " tensor([[[[1., 1., 1.,  ..., 0., 0., 0.],\n",
       "           [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "           [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "           [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "           [1., 1., 1.,  ..., 0., 0., 0.]]]], device='cuda:0'),\n",
       " tensor([[[[0., 0., 0.,  ..., 1., 1., 1.],\n",
       "           [0., 0., 0.,  ..., 1., 1., 1.],\n",
       "           [0., 0., 0.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 1., 1., 1.],\n",
       "           [0., 0., 0.,  ..., 1., 1., 1.],\n",
       "           [0., 0., 0.,  ..., 1., 1., 1.]]]], device='cuda:0'),\n",
       " tensor([[[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]]], device='cuda:0'),\n",
       " tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.]]]], device='cuda:0')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks = [x.to(config.DEVICE) for x in mask_loader]\n",
    "masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 512, 512])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'coarse'\n",
    "\n",
    "results_path = os.path.join(config.PATH, 'results')\n",
    "if hasattr(config, 'RESULTS'):\n",
    "    results_path = os.path.join(config.RESULTS)\n",
    "\n",
    "if hasattr(config, 'DEBUG') and config.DEBUG != 0:\n",
    "    debug = True\n",
    "\n",
    "log_file = os.path.join(config.PATH, 'log_' + model_name + '.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': Dataset ImageFolder\n",
       "     Number of datapoints: 209\n",
       "     Root location: ./dataset/mvtec/bottle/train\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                Resize(size=512, interpolation=bilinear, max_size=None, antialias=None)\n",
       "                CenterCrop(size=(512, 512))\n",
       "                ToTensor()\n",
       "            ),\n",
       " 'test': Dataset ImageFolder\n",
       "     Number of datapoints: 83\n",
       "     Root location: ./dataset/mvtec/bottle/test\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                Resize(size=512, interpolation=bilinear, max_size=None, antialias=None)\n",
       "                CenterCrop(size=(512, 512))\n",
       "                ToTensor()\n",
       "            ),\n",
       " 'train4val': Dataset ImageFolder\n",
       "     Number of datapoints: 209\n",
       "     Root location: ./dataset/mvtec/bottle/train\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                Resize(size=512, interpolation=bilinear, max_size=None, antialias=None)\n",
       "                CenterCrop(size=(512, 512))\n",
       "                ToTensor()\n",
       "            )}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 209\n",
       "    Root location: ./dataset/mvtec/bottle/train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=512, interpolation=bilinear, max_size=None, antialias=None)\n",
       "               CenterCrop(size=(512, 512))\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader = dataset['train']\n",
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.experiments.ExpMvtec at 0x7fc60f4045c0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x7fc607468fd0>,\n",
       " 'test': <torch.utils.data.dataloader.DataLoader at 0x7fc6637ca9e8>,\n",
       " 'train4val': <torch.utils.data.dataloader.DataLoader at 0x7fc607468f28>}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def imshow(img):\n",
    "    np_img = img.numpy()\n",
    "    plt.imshow((np.transpose(np_img, (1,2,0))).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 512, 512])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader = dataset['train']\n",
    "dataiter = iter(train_loader)\n",
    "imgs, labels = next(dataiter)\n",
    "imgs.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inpainting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BaseNetwork, self).__init__()\n",
    "\n",
    "    def init_weights(self, init_type='normal', gain=0.02):\n",
    "        '''\n",
    "        initialize network's weights\n",
    "        init_type: normal | xavier | kaiming | orthogonal\n",
    "        https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/9451e70673400885567d08a9e97ade2524c700d0/models/networks.py#L39\n",
    "        '''\n",
    "        def init_func(m):\n",
    "            classname = m.__class__.__name__\n",
    "            if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n",
    "                if init_type == 'normal':\n",
    "                    nn.init.normal_(m.weight.data, 0.0, gain)\n",
    "                elif init_type == 'xavier':\n",
    "                    nn.init.xavier_normal_(m.weight.data, gain=gain)\n",
    "                elif init_type == 'kaiming':\n",
    "                    nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "                elif init_type == 'orthogonal':\n",
    "                    nn.init.orthogonal_(m.weight.data, gain=gain)\n",
    "\n",
    "                if hasattr(m, 'bias') and m.bias is not None:\n",
    "                    nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "            elif classname.find('BatchNorm2d') != -1:\n",
    "                nn.init.normal_(m.weight.data, 1.0, gain)\n",
    "                nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "        self.apply(init_func)\n",
    "\n",
    "class InpaintGenerator(BaseNetwork):\n",
    "    def __init__(self, residual_blocks=8, init_weights=True, in_channels=3):\n",
    "        super(InpaintGenerator, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=64, kernel_size=7, padding=0),\n",
    "            nn.InstanceNorm2d(64, track_running_stats=False),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(128, track_running_stats=False),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(256, track_running_stats=False),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(256, track_running_stats=False),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        blocks = []\n",
    "        for _ in range(residual_blocks):\n",
    "            block = ResnetBlock(512, 2)  # dilation\n",
    "            blocks.append(block)\n",
    "\n",
    "        self.middle = nn.Sequential(*blocks)\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            nn.Conv2d(in_channels=512, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.InstanceNorm2d(128, track_running_stats=False),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            nn.Conv2d(in_channels=256, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.InstanceNorm2d(128, track_running_stats=False),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            nn.Conv2d(in_channels=128, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.InstanceNorm2d(64, track_running_stats=False),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(in_channels=64, out_channels=in_channels, kernel_size=7, padding=0),\n",
    "        )\n",
    "\n",
    "        if init_weights:\n",
    "            self.init_weights()\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        x = self.encoder(x)\n",
    "        x = self.middle(x)\n",
    "        x = self.decoder(x)\n",
    "        x = (torch.tanh(x) + 1) / 2\n",
    "        return x\n",
    "\n",
    "class Discriminator(BaseNetwork):\n",
    "    def __init__(self, in_channels, use_sigmoid=True, use_spectral_norm=True, init_weights=True):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.use_sigmoid = use_sigmoid\n",
    "\n",
    "        self.conv1 = self.features = nn.Sequential(\n",
    "            spectral_norm(nn.Conv2d(in_channels=in_channels, out_channels=64, kernel_size=4, stride=2, padding=1, bias=not use_spectral_norm), use_spectral_norm),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            spectral_norm(nn.Conv2d(in_channels=64, out_channels=128, kernel_size=4, stride=2, padding=1, bias=not use_spectral_norm), use_spectral_norm),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            spectral_norm(nn.Conv2d(in_channels=128, out_channels=256, kernel_size=4, stride=2, padding=1, bias=not use_spectral_norm), use_spectral_norm),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "\n",
    "        self.conv4 = nn.Sequential(\n",
    "            spectral_norm(nn.Conv2d(in_channels=256, out_channels=512, kernel_size=4, stride=1, padding=1, bias=not use_spectral_norm), use_spectral_norm),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "\n",
    "        self.conv5 = nn.Sequential(\n",
    "            spectral_norm(nn.Conv2d(in_channels=512, out_channels=1, kernel_size=4, stride=1, padding=1, bias=not use_spectral_norm), use_spectral_norm),\n",
    "        )\n",
    "\n",
    "        if init_weights:\n",
    "            self.init_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1 = self.conv1(x)\n",
    "        conv2 = self.conv2(conv1)\n",
    "        conv3 = self.conv3(conv2)\n",
    "        conv4 = self.conv4(conv3)\n",
    "        conv5 = self.conv5(conv4)\n",
    "\n",
    "        outputs = conv5\n",
    "        if self.use_sigmoid:\n",
    "            outputs = torch.sigmoid(conv5)\n",
    "\n",
    "        return outputs, [conv1, conv2, conv3, conv4, conv5]\n",
    "\n",
    "class ResnetBlock(nn.Module):\n",
    "    def __init__(self, dim, dilation=1, use_spectral_norm=False):\n",
    "        super(ResnetBlock, self).__init__()\n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.ReflectionPad2d(dilation),\n",
    "            spectral_norm(nn.Conv2d(in_channels=dim, out_channels=dim, kernel_size=3, padding=0, dilation=dilation, bias=not use_spectral_norm), use_spectral_norm),\n",
    "            # spectral_norm(nn.Conv2d(in_channels=dim, out_channels=dim, kernel_size=3, padding=1, bias=not use_spectral_norm), use_spectral_norm),\n",
    "            nn.InstanceNorm2d(dim, track_running_stats=False),\n",
    "            nn.ReLU(True),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            spectral_norm(nn.Conv2d(in_channels=dim, out_channels=dim, kernel_size=3, padding=0, dilation=1, bias=not use_spectral_norm), use_spectral_norm),\n",
    "            # spectral_norm(nn.Conv2d(in_channels=dim, out_channels=dim, kernel_size=3, padding=1, bias=not use_spectral_norm), use_spectral_norm),\n",
    "            nn.InstanceNorm2d(dim, track_running_stats=False),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x + self.conv_block(x)\n",
    "        # Remove ReLU at the end of the residual block\n",
    "        # http://torch.ch/blog/2016/02/04/resnets.html\n",
    "        return out\n",
    "\n",
    "def spectral_norm(module, mode=True):\n",
    "    if mode:\n",
    "        return nn.utils.spectral_norm(module)\n",
    "    return module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from src.loss import AdversarialLoss\n",
    "\n",
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, name, config):\n",
    "        super(BaseModel, self).__init__()\n",
    "\n",
    "        self.name = name\n",
    "        self.config = config\n",
    "        self.iteration = 0\n",
    "        self.epoch = 0\n",
    "\n",
    "        self.gen_weights_path = os.path.join(config.PATH, name + '_gen.pth')\n",
    "        self.dis_weights_path = os.path.join(config.PATH, name + '_dis.pth')\n",
    "\n",
    "    def load(self):\n",
    "        if os.path.exists(self.gen_weights_path):\n",
    "            print('Loading %s generator...' % self.name)\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                data = torch.load(self.gen_weights_path)\n",
    "            else:\n",
    "                data = torch.load(self.gen_weights_path, map_location=lambda storage, loc: storage)\n",
    "\n",
    "            self.generator.load_state_dict(data['generator'])\n",
    "            self.iteration = data['iteration']\n",
    "            self.epoch = data['epoch']\n",
    "\n",
    "        # load discriminator only when training\n",
    "        if self.config.MODE == 1 and os.path.exists(self.dis_weights_path):\n",
    "            print('Loading %s discriminator...' % self.name)\n",
    "\n",
    "            # update weights\n",
    "            if torch.cuda.is_available():\n",
    "                data = torch.load(self.dis_weights_path)\n",
    "            else:\n",
    "                data = torch.load(self.dis_weights_path, map_location=lambda storage, loc: storage)\n",
    "\n",
    "            self.discriminator.load_state_dict(data['discriminator'])\n",
    "\n",
    "    def save(self):\n",
    "        print('\\nsaving %s...\\n' % self.name)\n",
    "        torch.save({\n",
    "            'iteration': self.iteration,\n",
    "            'epoch': self.epoch,\n",
    "            'generator': self.generator.state_dict()\n",
    "        }, self.gen_weights_path)\n",
    "\n",
    "        torch.save({\n",
    "            'discriminator': self.discriminator.state_dict()\n",
    "        }, self.dis_weights_path)\n",
    "\n",
    "class InpaintingModel(BaseModel):\n",
    "\n",
    "    def __init__(self, config, append_name=''):\n",
    "        super(InpaintingModel, self).__init__('InpaintingModel'+str(append_name), config)\n",
    "\n",
    "        # generator input: [rgb(3)]\n",
    "        # discriminator input: [rgb(3)]\n",
    "        generator = InpaintGenerator(in_channels=config.INPUT_CHANNELS)\n",
    "\n",
    "        discriminator = Discriminator(in_channels=config.INPUT_CHANNELS, use_sigmoid=config.GAN_LOSS != 'hinge')\n",
    "\n",
    "\n",
    "        if len(config.GPU) > 1:\n",
    "            generator = nn.DataParallel(generator, config.GPU)\n",
    "            discriminator = nn.DataParallel(discriminator, config.GPU)\n",
    "\n",
    "        l1_loss = nn.MSELoss()\n",
    "        adversarial_loss = AdversarialLoss(type=config.GAN_LOSS)\n",
    "\n",
    "        self.add_module('generator', generator)\n",
    "        self.add_module('discriminator', discriminator)\n",
    "\n",
    "        self.add_module('l1_loss', l1_loss)\n",
    "        self.add_module('adversarial_loss', adversarial_loss)\n",
    "\n",
    "        self.gen_optimizer = optim.Adam(\n",
    "            params=generator.parameters(),\n",
    "            lr=float(config.LR),\n",
    "            betas=(config.BETA1, config.BETA2)\n",
    "        )\n",
    "\n",
    "        self.dis_optimizer = optim.Adam(\n",
    "            params=discriminator.parameters(),\n",
    "            lr=float(config.LR) * float(config.D2G_LR),\n",
    "            betas=(config.BETA1, config.BETA2)\n",
    "        )\n",
    "\n",
    "    def process(self, images, masks=None):\n",
    "        self.iteration += 1\n",
    "\n",
    "        # zero optimizers\n",
    "        self.gen_optimizer.zero_grad()\n",
    "        self.dis_optimizer.zero_grad()\n",
    "\n",
    "        # process outputs\n",
    "        outputs = self(images, masks)\n",
    "        gen_loss = 0\n",
    "        dis_loss = 0\n",
    "\n",
    "        # discriminator loss\n",
    "        dis_input_real = images\n",
    "        dis_input_fake = outputs.detach()\n",
    "        dis_real, dis_real_feat = self.discriminator(dis_input_real)                    # in: [rgb(3)]\n",
    "        dis_fake, _ = self.discriminator(dis_input_fake)                    # in: [rgb(3)]\n",
    "        dis_real_loss = self.adversarial_loss(dis_real, True, True)\n",
    "        dis_fake_loss = self.adversarial_loss(dis_fake, False, True)\n",
    "        dis_loss += (dis_real_loss + dis_fake_loss) / 2\n",
    "\n",
    "        # generator adversarial loss\n",
    "        gen_input_fake = outputs\n",
    "        gen_fake, gen_fake_feat = self.discriminator(gen_input_fake)                    # in: [rgb(3)]\n",
    "        gen_gan_loss = self.adversarial_loss(gen_fake, True, False) * self.config.INPAINT_ADV_LOSS_WEIGHT\n",
    "        gen_loss += gen_gan_loss\n",
    "\n",
    "        # generator l1 loss\n",
    "        if masks is not None:\n",
    "            gen_l1_loss_back = self.l1_loss(outputs*(1-masks).float(), images*(1-masks).float())\n",
    "            gen_l1_loss_crop = self.l1_loss(outputs*masks.float(), images*masks.float())\n",
    "            gen_l1_loss = (gen_l1_loss_back + 4 * gen_l1_loss_crop) * self.config.REC_LOSS_WEIGHT / torch.mean(masks)\n",
    "        else:\n",
    "            gen_l1_loss = self.l1_loss(outputs, images) * self.config.REC_LOSS_WEIGHT\n",
    "        gen_loss += gen_l1_loss\n",
    "\n",
    "        # generator feature matching loss\n",
    "        gen_fm_loss = 0\n",
    "        for i in range(len(dis_real_feat)):\n",
    "            gen_fm_loss += nn.MSELoss()(gen_fake_feat[i], dis_real_feat[i].detach())\n",
    "        gen_fm_loss = gen_fm_loss * self.config.FM_LOSS_WEIGHT\n",
    "        gen_loss += gen_fm_loss\n",
    "\n",
    "        logs = {\n",
    "            \"l_dis\": dis_loss.item(),\n",
    "            \"l_dis_real\": dis_real_loss.item(),\n",
    "            \"l_dis_fake\": dis_fake_loss.item(),\n",
    "            \"l_gen_gan\": gen_gan_loss.item(),\n",
    "            \"l_l1\": gen_l1_loss.item(),\n",
    "            \"l_fm\": gen_fm_loss.item(),\n",
    "            \"l_gen_sum\": gen_loss.item(),\n",
    "        }\n",
    "\n",
    "        return outputs, gen_loss, dis_loss, logs\n",
    "\n",
    "    def forward(self, images, masks=None):\n",
    "        if masks is not None:\n",
    "            images_masked = (images * (1 - masks).float()) + masks\n",
    "            inputs = images_masked\n",
    "            if masks.size(0) == 1:\n",
    "                masks = masks.expand(inputs.size()[0], -1, -1, -1)\n",
    "            outputs = self.generator(inputs, masks)  # in: [rgb(3)]\n",
    "        else:\n",
    "            inputs = images\n",
    "            outputs = self.generator(inputs)                                    # in: [rgb(3)]\n",
    "        return outputs\n",
    "\n",
    "    def backward(self, gen_loss=None, dis_loss=None):\n",
    "        dis_loss.backward()\n",
    "        self.dis_optimizer.step()\n",
    "\n",
    "        gen_loss.backward()\n",
    "        self.gen_optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InpaintingModel(\n",
       "  (generator): InpaintGenerator(\n",
       "    (encoder): Sequential(\n",
       "      (0): ReflectionPad2d((3, 3, 3, 3))\n",
       "      (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
       "      (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (9): ReLU(inplace=True)\n",
       "      (10): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (11): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (12): ReLU(inplace=True)\n",
       "    )\n",
       "    (middle): Sequential(\n",
       "      (0): ResnetBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): ReflectionPad2d((2, 2, 2, 2))\n",
       "          (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\n",
       "          (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (1): ResnetBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): ReflectionPad2d((2, 2, 2, 2))\n",
       "          (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\n",
       "          (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (2): ResnetBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): ReflectionPad2d((2, 2, 2, 2))\n",
       "          (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\n",
       "          (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (3): ResnetBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): ReflectionPad2d((2, 2, 2, 2))\n",
       "          (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\n",
       "          (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (4): ResnetBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): ReflectionPad2d((2, 2, 2, 2))\n",
       "          (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\n",
       "          (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (5): ResnetBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): ReflectionPad2d((2, 2, 2, 2))\n",
       "          (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\n",
       "          (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (6): ResnetBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): ReflectionPad2d((2, 2, 2, 2))\n",
       "          (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\n",
       "          (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (7): ResnetBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): ReflectionPad2d((2, 2, 2, 2))\n",
       "          (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\n",
       "          (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (5): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (7): ReLU(inplace=True)\n",
       "      (8): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (9): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (10): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): ReflectionPad2d((3, 3, 3, 3))\n",
       "      (13): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (discriminator): Discriminator(\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (conv3): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (conv4): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (conv5): Sequential(\n",
       "      (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (l1_loss): MSELoss()\n",
       "  (adversarial_loss): AdversarialLoss(\n",
       "    (criterion): BCELoss()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.inpaint_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InpaintGenerator(\n",
       "  (encoder): Sequential(\n",
       "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
       "    (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
       "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (11): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (12): ReLU(inplace=True)\n",
       "  )\n",
       "  (middle): Sequential(\n",
       "    (0): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((2, 2, 2, 2))\n",
       "        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\n",
       "        (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (1): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((2, 2, 2, 2))\n",
       "        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\n",
       "        (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (2): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((2, 2, 2, 2))\n",
       "        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\n",
       "        (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (3): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((2, 2, 2, 2))\n",
       "        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\n",
       "        (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (4): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((2, 2, 2, 2))\n",
       "        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\n",
       "        (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (5): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((2, 2, 2, 2))\n",
       "        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\n",
       "        (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (6): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((2, 2, 2, 2))\n",
       "        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\n",
       "        (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (7): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((2, 2, 2, 2))\n",
       "        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\n",
       "        (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (5): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (9): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (10): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): ReflectionPad2d((3, 3, 3, 3))\n",
       "    (13): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.inpaint_model.generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "  )\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "  )\n",
       "  (conv4): Sequential(\n",
       "    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "  )\n",
       "  (conv5): Sequential(\n",
       "    (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.inpaint_model.discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "val:\n",
      "209/209 [====================] - 108s 517ms/step - index: 25.6268\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.41785451769828796"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "test:\n",
      "83/83 [====================] - 44s 531ms/step - index: 9.8795\n",
      "0.2238095238095238\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2238095238095238"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.test()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "update normalization parameter:\n",
      "209/209 [====================] - 110s 528ms/step - index: 25.6268\n",
      "updated norm: [0.22931867837905884, 0.2315831184387207, 0.2428763061761856]\n",
      "\n",
      "start testing...\n",
      "\n",
      "\n",
      "\n",
      "test:\n",
      "83/83 [====================] - 45s 537ms/step - index: 9.8795\n",
      "0.27063492063492056\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.27063492063492056"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.MODE = 2\n",
    "\n",
    "model.update_norm()\n",
    "print('\\nstart testing...\\n')\n",
    "model.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_norm(self):\n",
    "    print('\\n\\nupdate normalization parameter:')\n",
    "    val_loader = self.dataset['train4val']\n",
    "\n",
    "    total = len(val_loader.dataset)\n",
    "    self.inpaint_model.eval()\n",
    "\n",
    "    mean_error_scales = {str(i): 0 for i in self.config.SCALES}\n",
    "    progbar = Progbar(total, width=20, stateful_metrics=['it'])\n",
    "    for index, items in enumerate(val_loader):\n",
    "        images, masks = self.cuda(*items[0:2])\n",
    "        # inpaint model\n",
    "        error1_list, mix_out_list_x, mix_out_list_y = self.get_error_map_for_some_scales(images, self.masks, metric='MSE',\n",
    "                                                                        scales=self.config.SCALES, output=True)\n",
    "        for i, scale in enumerate(self.config.SCALES):\n",
    "            mean_error_scales[str(scale)] += torch.mean(error1_list[i]) * len(items[0]) / total\n",
    "        progbar.add(len(images), values=[('index', index)])\n",
    "    # update\n",
    "    for i, scale in enumerate(self.config.SCALES):\n",
    "        self.scale_norm[i] = mean_error_scales[str(scale)].item()\n",
    "    print('updated norm:', self.scale_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error_map_for_some_scales(self, images, mask_loader, metric='MSE', scales=None, output=False):\n",
    "    if metric == 'MSE':\n",
    "        error_metric = nn.MSELoss(reduction='none')\n",
    "    else:\n",
    "        error_metric = nn.L1Loss(reduction='none')\n",
    "    with torch.no_grad():\n",
    "        error_map_list = []\n",
    "        mix_output_x = []\n",
    "        mix_output_y = []\n",
    "        for scale in scales:\n",
    "            error = []\n",
    "            raw_output = []\n",
    "            for masks in mask_loader[scale*4:(scale+1)*4]:\n",
    "                outputs = self.inpaint_model(images, masks)\n",
    "                if output:\n",
    "                    raw_output.append(outputs*masks)\n",
    "                error.append(torch.mean(error_metric(outputs, images) * masks, 1))  # mean RGB channel\n",
    "            if output:\n",
    "                raw_output = torch.stack(raw_output)\n",
    "                mix_output_x.append(torch.sum(raw_output[0:2], 0))\n",
    "                mix_output_y.append(torch.sum(raw_output[2:4], 0))\n",
    "            error = torch.stack(tuple(error))\n",
    "            # error_map_list.append(torch.sum(error * 0.5, 0))\n",
    "            error_map_list.append(torch.max(error, 0)[0])\n",
    "\n",
    "    return error_map_list, mix_output_x, mix_output_y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
